{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ceb06e56607af30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:26:13.419405Z",
     "start_time": "2024-04-10T17:26:13.400649Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6074fee6f9c3633a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:23:40.920224Z",
     "start_time": "2024-04-10T17:23:40.691749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd:  /Users/gbemidebe/Documents/GitHub/knnGuidedDesign\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "os.chdir('../')\n",
    "print('cwd: ', os.getcwd())\n",
    "from src.arch.model import VAE\n",
    "from src.arch.lightning import trainerVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487be20b82a6301c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:30:59.696517Z",
     "start_time": "2024-04-10T17:30:59.637024Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_pretrained_weight_path = 'reports/VAE/hyper_search_checkpoints/50/best-chckpt.ckpt'\n",
    "vae_pretrained = torch.load(vae_pretrained_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ecde9666701f4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:31:11.727464Z",
     "start_time": "2024-04-10T17:31:11.653463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'dec_hidden_dim_1': 16,\n",
       " 'dec_hidden_dim_2': 16,\n",
       " 'dropout': 0.2,\n",
       " 'enc_hidden_dim_1': 16,\n",
       " 'enc_hidden_dim_2': 16,\n",
       " 'height_dim': 41,\n",
       " 'input_dim': 2378,\n",
       " 'latent_dim': 32,\n",
       " 'learning_rate': 0.001,\n",
       " 'max_len': 58,\n",
       " 'num_epochs': 500,\n",
       " 'seed': 1994,\n",
       " 'split_ratio': 0.3,\n",
       " 'width_dim': 58}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_pretrained_params_path = 'reports/VAE/hyper_search_logs/knnMoleculeVAE/version_50/hparams.yaml'\n",
    "vae_pretrained_params = yaml.safe_load(open(vae_pretrained_params_path))\n",
    "vae_pretrained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b5d36858aee3cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:35:23.570249Z",
     "start_time": "2024-04-10T17:35:23.548503Z"
    }
   },
   "outputs": [],
   "source": [
    "vae = trainerVAE(\n",
    "        input_dim=int(vae_pretrained_params['input_dim']), \n",
    "        latent_dim=int(vae_pretrained_params['latent_dim']),\n",
    "        enc_hidden_dim_1 = int(vae_pretrained_params['enc_hidden_dim_1']), \n",
    "        enc_hidden_dim_2 = int(vae_pretrained_params['enc_hidden_dim_2']), \n",
    "        dec_hidden_dim_1=int(vae_pretrained_params['dec_hidden_dim_1']),\n",
    "        dec_hidden_dim_2=int(vae_pretrained_params['dec_hidden_dim_2']), \n",
    "        dropout=float(vae_pretrained_params['dropout'])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff01cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0066,  0.0136,  0.0114,  ..., -0.0100,  0.0070,  0.0125],\n",
       "        [-0.0192, -0.0149, -0.0054,  ..., -0.0032,  0.0143,  0.0125],\n",
       "        [-0.0112, -0.0133,  0.0114,  ..., -0.0026,  0.0190,  0.0125],\n",
       "        ...,\n",
       "        [ 0.0029, -0.0136,  0.0077,  ..., -0.0117,  0.0149,  0.0017],\n",
       "        [-0.0063, -0.0065, -0.0084,  ..., -0.0149, -0.0004,  0.0045],\n",
       "        [ 0.0112, -0.0013, -0.0009,  ..., -0.0138,  0.0074,  0.0093]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encoder[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9265eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.load_state_dict(vae_pretrained['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a20989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0009, -0.0188,  0.0189,  ...,  0.0080,  0.0167, -0.0010],\n",
       "        [-0.0007,  0.0171, -0.0101,  ..., -0.0107,  0.0116,  0.0018],\n",
       "        [-0.0072,  0.0031, -0.0067,  ...,  0.0175, -0.0016, -0.0029],\n",
       "        ...,\n",
       "        [ 0.0045,  0.0126,  0.0094,  ...,  0.0011,  0.0002,  0.0184],\n",
       "        [-0.0085, -0.0157, -0.0005,  ...,  0.0026, -0.0041, -0.0191],\n",
       "        [ 0.0020, -0.0156, -0.0038,  ..., -0.0154,  0.0193,  0.0177]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encoder[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e823843e1f99959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:37:40.801875Z",
     "start_time": "2024-04-10T17:37:40.300188Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/miniconda3/envs/MatML/lib/python3.8/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0009, -0.0188,  0.0189,  ...,  0.0080,  0.0167, -0.0010],\n",
       "        [-0.0007,  0.0171, -0.0101,  ..., -0.0107,  0.0116,  0.0018],\n",
       "        [-0.0072,  0.0031, -0.0067,  ...,  0.0175, -0.0016, -0.0029],\n",
       "        ...,\n",
       "        [ 0.0045,  0.0126,  0.0094,  ...,  0.0011,  0.0002,  0.0184],\n",
       "        [-0.0085, -0.0157, -0.0005,  ...,  0.0026, -0.0041, -0.0191],\n",
       "        [ 0.0020, -0.0156, -0.0038,  ..., -0.0154,  0.0193,  0.0177]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_pretrained['state_dict']['encoder.0.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbff03",
   "metadata": {},
   "source": [
    "# Generate new molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e99b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2378, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(vae_pretrained_params['input_dim']), int(vae_pretrained_params['latent_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff951390a1ac8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 2378])\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    samples = torch.randn(500, int(vae_pretrained_params['latent_dim']))\n",
    "    decoded_samples = vae.decoder(samples)\n",
    "\n",
    "print(decoded_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76a6d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 64])\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    encoded_samples = vae.encoder(decoded_samples)\n",
    "\n",
    "print(encoded_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2304d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Translating SMILES to SELFIES...0%\n",
      "--> Finished translating SMILES to SELFIES...100%\n",
      "--> Creating one-hot encoding...0%\n",
      "--> Finished creating one-hot encoding...100%\n"
     ]
    }
   ],
   "source": [
    "from src.data.loader import load_vae_data\n",
    "_, _, _, selfies_alphabet, \\\n",
    "                    largest_selfies_len, vocab_stoi, vocab_itos = load_vae_data(seed=1004, test_size=0.2, csv_path='./data/pretrain_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import generated_molecules_to_smiles, valid_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8eadc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Converting arrays to smiles...0%\n",
      "--> Finished converting arrays to smiles...100%\n",
      "--> Percentage of valid SMILES strings: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# decoded to smiles\n",
    "decoded_samples_smiles = generated_molecules_to_smiles(\n",
    "                        generated_molecules = decoded_samples, \n",
    "                        width = int(vae_pretrained_params['width_dim']), \n",
    "                        height = int(vae_pretrained_params['height_dim']),\n",
    "                        vocab_itos = vocab_itos)\n",
    "decoded_samples_smiles = valid_smiles(decoded_samples_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ce7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "def show_both_chemical_space(\n",
    "                        redox_potential: list, \n",
    "                             vae_pretain_data: list, \n",
    "                             figsize = (14, 6)):\n",
    "    \"\"\"\n",
    "    Plot a t-SNE plot of the molecular fingerprints for a list of SMILES strings\n",
    "    params:\n",
    "            redox_potential: a list of SMILES strings\n",
    "            vae_pretain_data: a list of SMILES strings\n",
    "    returns:\n",
    "    fig: matplotlib figure of scatter plot and make sure they are legende based on input parameters\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, facecolor='w', figsize=figsize)\n",
    "    # Generate molecular fingerprints using Morgan algorithm with radius=2\n",
    "    smiles = redox_potential + vae_pretain_data # merge into 1 list\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(sm), 2) for sm in smiles]\n",
    "    # Convert the list of fingerprints to a numpy array\n",
    "    fps = np.asarray([AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(sm), 2) for sm in smiles])\n",
    "    tsne_ = TSNE(n_components=2)\n",
    "    pca_ = PCA(n_components=2)\n",
    "    umap_ = umap.UMAP(n_neighbors = 25, n_components = 2, low_memory = False, min_dist = 0.001)\n",
    "    tsne_result = tsne_.fit_transform(fps)\n",
    "    pca_result = pca_.fit_transform(fps)\n",
    "    umap_result = umap_.fit_transform(fps)\n",
    "    \n",
    "    # index redox_potential and then vae_pretrain_data\n",
    "    redox_potential_pos = range(len(redox_potential))\n",
    "    vae_pretain_pos = range(len(redox_potential), len(redox_potential)+len(vae_pretain_data))\n",
    "    \n",
    "    ax[0].scatter(pca_result[redox_potential_pos][:, 0], pca_result[redox_potential_pos][:, 1], label='FT')\n",
    "    ax[0].scatter(tsne_result[vae_pretain_pos][:,0], tsne_result[vae_pretain_pos][:,1], label = 'PT')\n",
    "    ax[0].set_xlabel(r'$\\rm PCA \\ 1$', fontsize = 20)\n",
    "    ax[0].set_ylabel(r'$\\rm PCA \\ 2$', fontsize = 20)\n",
    "    ax[0].tick_params(axis='x', labelsize=18)\n",
    "    ax[0].tick_params(axis='y', labelsize=18)\n",
    "    ax[0].grid(False)\n",
    "    \n",
    "    ax[1].scatter(tsne_result[redox_potential_pos][:,0], tsne_result[redox_potential_pos][:,1], label='FT')\n",
    "    ax[1].scatter(tsne_result[vae_pretain_pos][:,0], tsne_result[vae_pretain_pos][:,1], label='PT')\n",
    "    ax[1].set_xlabel(r'$\\rm tSNE \\ 1$', fontsize=20)\n",
    "    ax[1].set_ylabel(r'$\\rm tSNE \\ 2$', fontsize=20)\n",
    "    ax[1].tick_params(axis='x', labelsize=18)\n",
    "    ax[1].tick_params(axis='y', labelsize=18)\n",
    "    ax[1].grid(False)\n",
    "    ax[1].legend(loc='best', frameon=True, shadow=True)\n",
    "    \n",
    "    ax[2].scatter(umap_result[redox_potential_pos][:,0], umap_result[redox_potential_pos][:,1], label='FT')\n",
    "    ax[2].scatter(umap_result[vae_pretain_pos][:, 0], umap_result[vae_pretain_pos][:,1], label='PT')\n",
    "    ax[2].set_xlabel(r'$\\rm UMAP \\ 1$', fontsize=20)\n",
    "    ax[2].set_ylabel(r'$\\rm UMAP \\ 2$', fontsize=20)\n",
    "    ax[2].tick_params(axis='x', labelsize=18)\n",
    "    ax[2].tick_params(axis='y', labelsize=18)\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bee71f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(C)[S](C)(=O)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(C)(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1CS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1c[nH]nn1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              smiles\n",
       "0  CC(C)[S](C)(=O)=O\n",
       "1         COC(C)(C)C\n",
       "2              C=CCO\n",
       "3              C1CS1\n",
       "4         c1c[nH]nn1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_data = pd.read_csv('./data/pretrain_data.csv')\n",
    "pretrained_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737416b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
